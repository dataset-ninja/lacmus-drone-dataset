The authors of **LADD** dataset, developed by non-profit search and rescue volunteer organizations with a focus on locating missing individuals, collected the data using drones and employed machine learning tools for labeling. These images were captured from an altitude of 40-50 meters above the ground, and they portray individuals in different poses. 

The authors engaged in extensive discussions with various search engines and rescuers in an attempt to comprehend the visual characteristics of a person lost in a forest when viewed from an aerial perspective. Consequently, they accumulated unique statistics pertaining to 24 common positions where missing individuals are typically located. Then they proceeded to capture the Lacmus Drone Dataset (LaDD), with the initial version comprising more than 400 images. The data collection process primarily utilized DJI Mavic Pro and Phantom drones, operating at altitudes ranging from 50 to 100 meters, with image resolutions set at 3000x4000 pixels and an average human size representation of 50x100 pixels.

In total, the dataset comprises 1365 images, and the annotations for LADD are accessible in VOC format, specifically using Xmax, Ymax, Xmin, Ymin coordinates, as well as in YOLO format, using XYWH values.

Please, note that the dataset is constantly updating, and this version is relevant as of October, 2023